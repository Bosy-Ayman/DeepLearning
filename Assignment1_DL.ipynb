{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWWF31aIWvAZFElxNPJcfl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bosy-Ayman/DeepLearning/blob/main/Assignment1_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objective:\n",
        "\n",
        "In this assignment, you are required to implement a CNN to classify images of\n",
        "flowers into different categories using the Flowers Recognition Dataset. The dataset\n",
        "consists of images of 5 different types of flowers.\n",
        "The Flowers Recognition Dataset includes images from 5 classes:\n",
        "\n",
        "• Chamomile\n",
        "\n",
        "• Dandelion\n",
        "\n",
        "• Rose\n",
        "\n",
        "• Sunflower\n",
        "\n",
        "• Tulip\n",
        "\n",
        "You can find anything you want to know about the dataset and download it through\n",
        "this link."
      ],
      "metadata": {
        "id": "5qmD2WVr4_v_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this assignment, you are required to implement a CNN to classify images of\n",
        "flowers into different categories using the Flowers Recognition Dataset. The dataset consists of images of 5 different types of flowers.\n",
        "The Flowers Recognition Dataset includes images from 5 classes:\n",
        "\n",
        "• Chamomile\n",
        "\n",
        "• Dandelion\n",
        "\n",
        "• Rose\n",
        "\n",
        "• Sunflower\n",
        "\n",
        "• Tulip\n",
        "\n",
        "You can find anything you want to know about the dataset and download it through\n",
        "this link."
      ],
      "metadata": {
        "id": "XIg_yqSseFrt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cPls4B1ZDR0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
        "\n",
        "X = []\n",
        "Z = []\n",
        "\n",
        "def assign_label(flower_type):\n",
        "    if flower_type == 'daisy':\n",
        "        return 1\n",
        "    elif flower_type == 'dandelion':\n",
        "        return 2\n",
        "    elif flower_type == 'rose':\n",
        "        return 3\n",
        "    elif flower_type == 'sunflower':\n",
        "        return 4\n",
        "    elif flower_type == 'tulip':\n",
        "        return 0\n"
      ],
      "metadata": {
        "id": "1gND9U2qiUqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN Architecture\n",
        "1. Build a custom CNN model using Keras deep learning API.\n",
        "2. The CNN should consist of convolutional layers, max-pooling layers, and\n",
        "fully connected layers with the suitable activation function for each if needed.\n",
        "3. Experiment with the architecture by varying the number of layers, filter sizes,\n",
        "and types of activation functions. You must use at least two different\n",
        "variations of the architecture."
      ],
      "metadata": {
        "id": "y2Lf24hae3v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for flower_type in classes:\n",
        "    class_directory = os.path.join(inputdataset, flower_type)\n",
        "\n",
        "    max_pixel_values = []\n",
        "    min_pixel_values = []\n",
        "\n",
        "    for img_file in os.listdir(class_directory):\n",
        "        image = imread(os.path.join(class_directory, img_file))\n",
        "\n",
        "        max_pixel_values.append(image.max())\n",
        "        min_pixel_values.append(image.min())\n",
        "\n",
        "    max_value_per_class = np.max(max_pixel_values)\n",
        "    min_value_per_class = np.min(min_pixel_values)\n",
        "\n",
        "    print(\"***************************\")\n",
        "    print(f\"Flower Type: {flower_type}\")\n",
        "    print(f\"Maximum Pixel Value: {max_value_per_class}\")\n",
        "    print(f\"Minimum Pixel Value: {min_value_per_class}\")\n",
        "\n",
        "print(\"***************************\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "aHdVXP-feFAf",
        "outputId": "9f13df91-3534-4967-ac30-8def7f714926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'inputdataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2388f90f6662>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mflower_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mclass_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflower_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmax_pixel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmin_pixel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'inputdataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing\n",
        "1. Load and preprocess the images.\n",
        "2. Resize the images to a uniform size (e.g., 128x128 or 64x64 pixels).\n",
        "3. Normalize the pixel values.\n",
        "4. Split the dataset into training, validation, and test sets."
      ],
      "metadata": {
        "id": "imw6nnUkeojD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jg3ugvnRaevv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}