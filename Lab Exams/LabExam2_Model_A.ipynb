{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1><center></center></h1>\n",
        "<h1><center>DSAI 308</center></h1>\n",
        "<h1><center>Lab Exam 2 (Siamese & Autoencoders)</center></h1>\n",
        "<h2><center>Model A</center></h2>\n",
        "<h2><center>Exam Time: 60 minutes</center></h2>\n",
        "<h2><center>Turn on GPU</center></h2>\n"
      ],
      "metadata": {
        "id": "kvDEPATV3aHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exam Instructions**\n",
        "- You are allowed to open TensorFlow & PyTorch documentation, no other links or colabs. Any way of cheating will be directed to **ZERO GRADE**.\n",
        "- Close all the tabs in your browser and keep only the notebook tab and documentation tab open.\n",
        "- Close all the windows on your operating system except for the browser window.\n",
        "- keep your cell phone in your pocket or on your bag and make it on silent mode.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-eZry1O54OKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***References***\n",
        "\n",
        "1. [TensorFlow Documentation](https://www.tensorflow.org/api_docs/python/tf/all_symbols)\n",
        "2. [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)\n",
        "3. [Keras Documentation](https://keras.io)"
      ],
      "metadata": {
        "id": "qTZaifDqm1SX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 1 - Siamese Network for Similarity Learning**  \n",
        "\n",
        "Implement a **Siamese Network** to learn similarity between images from the **CIFAR-10 dataset**.\n",
        "\n",
        "### Instructions:\n",
        "\n",
        "1. **Load and Preprocess the CIFAR-10 Dataset:**\n",
        "   - Load the **CIFAR-10** dataset containing images of handwritten digits.\n",
        "   - Normalize the pixel values of images to the range `[0, 1]`.\n",
        "   - Create **pairs of images**:  \n",
        "     - Positive pairs: Images of the same digit.  \n",
        "     - Negative pairs: Images of different digits.\n",
        "\n",
        "2. **Build the Siamese Network:**\n",
        "   - **Base Network:**  \n",
        "     - Input: `(28, 28, 1)` image.\n",
        "     - Add **Conv2D** layers to extract features from the input images.\n",
        "     - Use **MaxPooling2D** to reduce spatial dimensions.\n",
        "     - Add a **Dense layer** to output a feature vector representing the input image.\n",
        "\n",
        "   - **Siamese Architecture:**  \n",
        "     - Use the base network to extract features from two input images.\n",
        "     - Compute the **L1 distance** between the feature vectors.\n",
        "     - Add a **Dense layer** with a sigmoid activation to predict similarity (1 = similar, 0 = dissimilar).\n",
        "\n",
        "3. **Train the Siamese Network:**\n",
        "   - Use the appropriate loss and optimizer.\n",
        "   - Train for at least **10 epochs** and do not forget the batch size, try to get +65% accuracy\n",
        "\n",
        "4. **Evaluate the Siamese Network:**\n",
        "   - Report the **test accuracy**\n",
        "\n"
      ],
      "metadata": {
        "id": "E62i_0wvNU81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1: Siamese Network on CIFAR-10\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "\n",
        "# Create pairs for Siamese Network\n",
        "def make_pairs(images, labels):\n",
        "    pairImages = []\n",
        "    pairLabels = []\n",
        "    numClasses = len(np.unique(labels))\n",
        "    idx = [np.where(labels == i)[0] for i in range(numClasses)]\n",
        "\n",
        "    for idxA in range(len(images)):\n",
        "        currentImage = images[idxA]\n",
        "        label = labels[idxA]\n",
        "\n",
        "        idxB = np.random.choice(idx[label])\n",
        "        posImage = images[idxB]\n",
        "\n",
        "        pairImages.append([currentImage, posImage])\n",
        "        pairLabels.append([1])\n",
        "\n",
        "        negIdx = np.where(labels != label)[0]\n",
        "        negImage = images[np.random.choice(negIdx)]\n",
        "\n",
        "        pairImages.append([currentImage, negImage])\n",
        "        pairLabels.append([0])\n",
        "\n",
        "    return np.array(pairImages), np.array(pairLabels)\n",
        "\n",
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    return tf.math.sqrt(tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True))\n",
        "\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\n",
        "trainX, trainY, testX, testY = trainX[:20000], trainY[:20000], testX[:20000], testY[:20000]\n",
        "\n",
        "trainY = trainY.flatten()\n",
        "testY = testY.flatten()\n",
        "x_train_val = trainX.astype(\"float32\")\n",
        "testX = testX.astype(\"float32\")"
      ],
      "metadata": {
        "id": "gG4nXqgxSdvR"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [0.5 mark] Preprocess input & apply pairs\n",
        "pairs_train, labels_train = make_pairs(trainX, trainY)\n",
        "\n",
        "# make validation pairs\n",
        "pairs_val, labels_val = make_pairs(testX, testY)\n",
        "\n",
        "# make test pairs\n",
        "pairs_test, labels_test = make_pairs(testX, testY)"
      ],
      "metadata": {
        "id": "jg5j6w_l1b_i"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIqxHUn1u_sB",
        "outputId": "8a5125fe-fedf-43de-faae-e2167a83443f"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import ops\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "xdWtdzxOvLAm"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [1.5 mark]\n",
        "\n",
        "# TODO: Define a CNN model\n",
        "# The model should contain Conv2D, relu, MaxPool2D, and Fully Connected layers\n",
        "# Define the CNN model for feature extraction\n",
        "# Build the Siamese Network\n",
        "input = keras.layers.Input((32, 32, 3))\n",
        "x = keras.layers.BatchNormalization()(input)\n",
        "x = keras.layers.Conv2D(4, (5, 5), activation=\"relu\")(x)\n",
        "x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = keras.layers.Conv2D(16, (5, 5), activation=\"relu\")(x)\n",
        "x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "x = keras.layers.Flatten()(x)\n",
        "\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Dense(10, activation=\"sigmoid\")(x)\n",
        "embedding_network = keras.Model(input, x)\n",
        "\n",
        "\n",
        "input_1 = keras.layers.Input((32, 32, 3))\n",
        "input_2 = keras.layers.Input((32, 32, 3))\n",
        "\n",
        "# As mentioned above, Siamese Network share weights between\n",
        "# tower networks (sister networks). To allow this, we will use\n",
        "# same embedding network for both tower networks.\n",
        "tower_1 = embedding_network(input_1)\n",
        "tower_2 = embedding_network(input_2)\n",
        "\n",
        "merge_layer = keras.layers.Lambda(euclidean_distance, output_shape=(1,))(\n",
        "    [tower_1, tower_2]\n",
        ")\n",
        "normal_layer = keras.layers.BatchNormalization()(merge_layer)\n",
        "output_layer = keras.layers.Dense(1, activation=\"sigmoid\")(normal_layer)\n",
        "siamese = keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
        "\n",
        "\n",
        "# Compute Euclidean distance & create output layer\n",
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    sum_square = ops.sum(ops.square(x - y), axis=1, keepdims=True)\n",
        "    return ops.sqrt(ops.maximum(sum_square, keras.backend.epsilon()))\n",
        "\n"
      ],
      "metadata": {
        "id": "NtyUi-EC1ep0"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [0.25 mark] TODO: Compile the model with  optimizer and loss function\n",
        "# Build and compile the model\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "margin = 1  # Margin for contrastive loss.\n",
        "def loss(margin=1):\n",
        "    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
        "    #                         true_value * square( max(margin-prediction, 0) ))\n",
        "    def contrastive_loss(y_true, y_pred):\n",
        "\n",
        "\n",
        "        square_pred = ops.square(y_pred)\n",
        "        margin_square = ops.square(ops.maximum(margin - (y_pred), 0))\n",
        "        return ops.mean((1 - y_true) * square_pred + (y_true) * margin_square)\n",
        "\n",
        "    return contrastive_loss\n",
        "siamese.compile(loss=loss(margin=margin), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "siamese.summary()"
      ],
      "metadata": {
        "id": "khdEjb9g1gCN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "289f29a3-d7e3-4e37-b1f2-dac02efebf33"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_21\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_21\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_30            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_31            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ functional_20             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │          \u001b[38;5;34m7,542\u001b[0m │ input_layer_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)              │                        │                │ input_layer_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda_8 (\u001b[38;5;33mLambda\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ functional_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ functional_20[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_27    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m4\u001b[0m │ lambda_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m2\u001b[0m │ batch_normalization_2… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_30            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_31            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ functional_20             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,542</span> │ input_layer_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │                        │                │ input_layer_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ functional_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ functional_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_27    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │ lambda_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ batch_normalization_2… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,548\u001b[0m (29.48 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,548</span> (29.48 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,740\u001b[0m (26.33 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,740</span> (26.33 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m808\u001b[0m (3.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">808</span> (3.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_1 = pairs_train[:, 0]  # x_train_1.shape is (60000, 28, 28)\n",
        "x_train_2 = pairs_train[:, 1]"
      ],
      "metadata": {
        "id": "BYbXIYjRwXh_"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_val_1 = pairs_val[:, 0]  # x_val_1.shape = (60000, 28, 28)\n",
        "x_val_2 = pairs_val[:, 1]"
      ],
      "metadata": {
        "id": "x6JK9BHZwZ1n"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [0.25 mark] TODO: Train the model for 5 epochs and evaluate it\n",
        "# Train the model\n",
        "history = siamese.fit(\n",
        "    [x_train_1, x_train_2],\n",
        "    labels_train,\n",
        "    validation_data=([x_val_1, x_val_2], labels_val),\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        ")\n"
      ],
      "metadata": {
        "id": "wJuDcjm5zoI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee2b14e-4772-49e4-fe50-914f4b5dd1a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.5980 - loss: 0.2368 - val_accuracy: 0.6506 - val_loss: 0.2161\n",
            "Epoch 2/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6441 - loss: 0.2196 - val_accuracy: 0.6561 - val_loss: 0.2143\n",
            "Epoch 3/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6476 - loss: 0.2169 - val_accuracy: 0.6677 - val_loss: 0.2077\n",
            "Epoch 4/5\n",
            "\u001b[1m1509/2500\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6578 - loss: 0.2131"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWttIp8k5ByK",
        "outputId": "795659a4-7dcd-4c9a-f6f0-1211e01ae0a3"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.5051000118255615,\n",
              "  0.6278749704360962,\n",
              "  0.6514999866485596,\n",
              "  0.659974992275238,\n",
              "  0.6665999889373779],\n",
              " 'loss': [0.25032278895378113,\n",
              "  0.22655034065246582,\n",
              "  0.21740593016147614,\n",
              "  0.2135920226573944,\n",
              "  0.2113029509782791],\n",
              " 'val_accuracy': [0.5864250063896179,\n",
              "  0.6641499996185303,\n",
              "  0.6640999913215637,\n",
              "  0.6743000149726868,\n",
              "  0.6796749830245972],\n",
              " 'val_loss': [0.23945613205432892,\n",
              "  0.21057458221912384,\n",
              "  0.20995672047138214,\n",
              "  0.20659877359867096,\n",
              "  0.20391547679901123]}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = siamese.evaluate([testX, testY],labels_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "QgIIqvPS3nMO",
        "outputId": "275b1c15-9172-4c11-ccc2-4a3a3f346dfc"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 10000, 10000\n'y' sizes: 20000\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-705d89031907>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiamese\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/data_adapter_utils.py\u001b[0m in \u001b[0;36mcheck_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    112\u001b[0m             )\n\u001b[1;32m    113\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"'{label}' sizes: {sizes}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 10000, 10000\n'y' sizes: 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 2 - Autoencoder for Image Reconstruction**  \n",
        "\n",
        "Design and train an **Autoencoder** to reconstruct images from the **CIFAR-10** dataset.\n",
        "\n",
        "### Instructions:\n",
        "\n",
        "1. **Load and Preprocess MNIST:**\n",
        "   - Load the **MNIST** dataset using `keras.datasets.MNIST.load_data()`.\n",
        "   - Normalize the pixel values of images to the range `[0, 1]`.\n",
        "\n",
        "2. **Build the Autoencoder Model:**\n",
        "   - **Encoder:**\n",
        "     - Input Layer: Take input of shape `(32, 32, 3)`.\n",
        "     - Add **Conv2D** layers to reduce the spatial dimensions using max pooling.\n",
        "     - Use **ReLU activation** for each layer.\n",
        "   - **Latent Space:**\n",
        "     - Add a Dense layer for the latent representation of the images.\n",
        "   - **Decoder:**\n",
        "     - Add **UpSampling2D** layers to reconstruct the original image size.\n",
        "     - Use **sigmoid activation** in the final layer to output the reconstructed image.\n",
        "\n",
        "3. **Train the Autoencoder:**\n",
        "   - Use the appropriate optimizer and loss function.\n",
        "   - Train for at least **10 epochs**\n"
      ],
      "metadata": {
        "id": "lUfojKsDN-1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Autoencoder on MNIST\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "# Load MNIST dataset\n",
        "(X_train, _), (X_test, _) = mnist.load_data()"
      ],
      "metadata": {
        "id": "XP3lpUSx2bNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df53d167-3128-45da-ec51-10cd1801c0f8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [0.5 mark] Preprocess images\n",
        "# Normalize data\n",
        "x_train = X_train.astype('float32') / 255.\n",
        "x_test = X_test.astype('float32') / 255.\n",
        "\n",
        "# Reshape data (add dimension)\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n",
        "\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "id": "9xYaEgLMvQNl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d939f70-0594-4aba-b74f-70d901983262"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Noise\n",
        "noise_factor = 0.5\n",
        "X_train_noise = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\n",
        "X_test_noise = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\n",
        "\n",
        "X_train_noise = np.clip(X_train_noise, 0., 1.)\n",
        "X_test_noise = np.clip(X_test_noise, 0., 1.)"
      ],
      "metadata": {
        "id": "SXEtaKXItEbp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [1.5 mark] Build Autoencoder model\n",
        "\n",
        "class Denoise(Model):\n",
        "  def __init__(self):\n",
        "    super(Denoise, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Input(shape=(28, 28, 1)),\n",
        "      layers.Conv2D(16, (3, 3), activation='sigmoid', padding='same', strides=2),\n",
        "      layers.Conv2D(8, (3, 3), activation='sigmoid', padding='same', strides=2)])\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='sigmoid', padding='same'),\n",
        "      layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='sigmoid', padding='same'),\n",
        "      layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = Denoise()"
      ],
      "metadata": {
        "id": "-6sjWAnSvRFD"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, losses\n"
      ],
      "metadata": {
        "id": "b4KHB5GzyE4Q"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [0.5 mark] TODO: Compile Train the model and validate on the test set + + early stopping\n",
        "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n"
      ],
      "metadata": {
        "id": "_uK24ZgkvUeu"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                                      patience=3)"
      ],
      "metadata": {
        "id": "YbEdUKlW0Yqa"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = autoencoder.fit(X_train_noise, x_train,\n",
        "                epochs=10,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test_noise, x_test),\n",
        "                callbacks=[callback]\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU5CyRVmyctk",
        "outputId": "f0f6a65b-ad77-4cb8-bd46-8018fc10221e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0075\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0076 - val_loss: 0.0075\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.0076 - val_loss: 0.0077\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.0075 - val_loss: 0.0075\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0075 - val_loss: 0.0074\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0075 - val_loss: 0.0073\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.0074 - val_loss: 0.0073\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0074 - val_loss: 0.0073\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0074 - val_loss: 0.0072\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.0073 - val_loss: 0.0073\n"
          ]
        }
      ]
    }
  ]
}